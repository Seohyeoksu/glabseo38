import json
import re
import time
import base64
from io import BytesIO
from typing import List, Dict, Tuple, Optional
from datetime import datetime
from pypdf import PdfReader

import streamlit as st
import pandas as pd
from openai import OpenAI, APIConnectionError, RateLimitError


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ì£¼ìš” ì•Œë ˆë¥´ê¸° ì •ë³´ (ì°¸ê³ ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAJOR_ALLERGENS = [
    "ìš°ìœ /ìœ ì œí’ˆ", "ë‹¬ê±€/ë‚œë¥˜", "ë•…ì½©", "ê²¬ê³¼ë¥˜", "ë°€/ê¸€ë£¨í…", 
    "ëŒ€ë‘/ì½©", "ìƒì„ /ì–´ë¥˜", "ê°‘ê°ë¥˜(ìƒˆìš°,ê²Œ,ëìŠ¤í„°)", "ì¡°ê°œë¥˜/íŒ¨ë¥˜",
    "ì°¸ê¹¨", "ì•„í™©ì‚°ì—¼", "ë©”ë°€", "ë¼ì§€ê³ ê¸°", "ì†Œê³ ê¸°", "ë‹­ê³ ê¸°",
    "ë³µìˆ­ì•„", "í† ë§ˆí† ", "í‚¤ìœ„", "ë°”ë‚˜ë‚˜", "ì•„ë³´ì¹´ë„"
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. AI ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_food_image_with_ai(
    image_bytes: bytes,
    api_key: str,
    model: str = "gpt-4o-mini",
    max_retries: int = 2,
) -> Dict:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ìŒì‹ê³¼ ì•Œë ˆë¥´ê¸° ì •ë³´ë¥¼ ìƒì„¸ ë¶„ì„"""
    client = OpenAI(api_key=api_key)
    b64 = base64.b64encode(image_bytes).decode()
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•™êµ ê¸‰ì‹ ì˜ì–‘ì‚¬ì´ì ì•Œë ˆë¥´ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì´ ì´ë¯¸ì§€ë¥¼ ë§¤ìš° ìì„¸íˆ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

    1. ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  ìŒì‹/ë©”ë‰´ë¥¼ ì‹ë³„í•˜ì„¸ìš”
    2. ê° ìŒì‹ì˜ ì¼ë°˜ì ì¸ ì¬ë£Œì™€ ì¡°ë¦¬ë²•ì„ ê³ ë ¤í•˜ì„¸ìš”
    3. ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° ìœ ë°œ ìš”ì†Œê¹Œì§€ ì°¾ì•„ë‚´ì„¸ìš”
    4. í•œêµ­ í•™êµ ê¸‰ì‹ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”

    ì£¼ìš” í™•ì¸ ì•Œë ˆë¥´ê¸°: {', '.join(MAJOR_ALLERGENS)}

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
        "menu_items": [
            {{
                "name": "ìŒì‹ëª…",
                "ingredients": ["ì£¼ì¬ë£Œ1", "ì£¼ì¬ë£Œ2", "ë¶€ì¬ë£Œ1", ...],
                "cooking_method": "ì¡°ë¦¬ ë°©ë²•",
                "allergens": [
                    {{
                        "allergen": "ì•Œë ˆë¥´ê¸° ìœ ë°œ ë¬¼ì§ˆ",
                        "source": "ì–´ë–¤ ì¬ë£Œì—ì„œ ìœ ë˜",
                        "risk_level": "ê³ ë„/ì¤‘ë“±ë„/ê²½ë„",
                        "hidden": true/false,
                        "cross_contamination": true/false
                    }}
                ],
                "nutrition_notes": "ì˜ì–‘í•™ì  íŠ¹ì§•"
            }}
        ],
        "overall_assessment": {{
            "total_allergens": ["ì „ì²´ ì•Œë ˆë¥´ê¸° ëª©ë¡"],
            "high_risk_items": ["ê³ ìœ„í—˜ í•­ëª©ë“¤"],
            "hidden_allergens": ["ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° ìœ ë°œ ìš”ì†Œ"],
            "safety_notes": "ì „ë°˜ì ì¸ ì•ˆì „ ì£¼ì˜ì‚¬í•­"
        }},
        "recommendations": {{
            "substitutions": ["ëŒ€ì²´ ê°€ëŠ¥í•œ ë©”ë‰´"],
            "preparation_tips": ["ì¡°ë¦¬ì‹œ ì£¼ì˜ì‚¬í•­"],
            "serving_guidelines": ["ë°°ì‹ì‹œ ì£¼ì˜ì‚¬í•­"]
        }}
    }}

    ì¤‘ìš”: 
    - ì¡°ë¯¸ë£Œ, ì†ŒìŠ¤, ì–‘ë…ì— ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° ì„±ë¶„ë„ ì°¾ì•„ì£¼ì„¸ìš”
    - êµì°¨ ì˜¤ì—¼ ê°€ëŠ¥ì„±ë„ í‰ê°€í•´ì£¼ì„¸ìš”
    - í•œêµ­ ìŒì‹ì˜ íŠ¹ì„±(ê³ ì¶”ì¥, ëœì¥, ìƒˆìš°ì “ ë“±)ì„ ê³ ë ¤í•˜ì„¸ìš”
    """
    
    for i in range(max_retries + 1):
        try:
            res = client.chat.completions.create(
                model=model,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64}"}}
                    ]
                }],
                temperature=0.3,
                max_tokens=2000
            )
            break
        except (RateLimitError, APIConnectionError):
            if i == max_retries:
                return {"error": "API í˜¸ì¶œ ì‹¤íŒ¨"}
            time.sleep(2 ** i)
    
    try:
        content = res.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            return {"error": "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", "raw": content}
    except json.JSONDecodeError:
        return {"error": "JSON íŒŒì‹± ì˜¤ë¥˜", "raw": content}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. AI ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_text_with_ai(
    text: str,
    api_key: str,
    model: str = "gpt-4o-mini",
    max_retries: int = 2,
) -> Dict:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì•Œë ˆë¥´ê¸° ì •ë³´ë¥¼ ìƒì„¸ ë¶„ì„"""
    client = OpenAI(api_key=api_key)
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•™êµ ê¸‰ì‹ ì˜ì–‘ì‚¬ì´ì ì•Œë ˆë¥´ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ í…ìŠ¤íŠ¸(ê¸‰ì‹ ë©”ë‰´ ë˜ëŠ” ì‹ë‹¨í‘œ)ë¥¼ ë¶„ì„í•˜ì—¬ ì•Œë ˆë¥´ê¸° ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

    í…ìŠ¤íŠ¸: {text}

    ì£¼ìš” í™•ì¸ ì•Œë ˆë¥´ê¸°: {', '.join(MAJOR_ALLERGENS)}

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
        "identified_menus": [
            {{
                "menu_name": "ë©”ë‰´ëª…",
                "likely_ingredients": ["ì¶”ì • ì¬ë£Œë“¤"],
                "allergen_analysis": [
                    {{
                        "allergen": "ì•Œë ˆë¥´ê¸° ìœ ë°œ ë¬¼ì§ˆ",
                        "confidence": "í™•ì‹¤í•¨/ê°€ëŠ¥ì„±ë†’ìŒ/ê°€ëŠ¥ì„±ìˆìŒ",
                        "source_ingredient": "ìœ ë˜ ì¬ë£Œ",
                        "risk_level": "ê³ ë„/ì¤‘ë“±ë„/ê²½ë„",
                        "notes": "ì¶”ê°€ ì„¤ëª…"
                    }}
                ]
            }}
        ],
        "summary": {{
            "total_allergens_found": ["ë°œê²¬ëœ ëª¨ë“  ì•Œë ˆë¥´ê¸°"],
            "high_confidence_allergens": ["í™•ì‹¤í•œ ì•Œë ˆë¥´ê¸°"],
            "possible_allergens": ["ê°€ëŠ¥ì„± ìˆëŠ” ì•Œë ˆë¥´ê¸°"],
            "menu_safety_score": "1-10ì ",
            "special_warnings": ["íŠ¹ë³„ ì£¼ì˜ì‚¬í•­"]
        }},
        "detailed_recommendations": {{
            "for_allergic_students": ["ì•Œë ˆë¥´ê¸° í•™ìƒì„ ìœ„í•œ ì¡°ì–¸"],
            "for_kitchen_staff": ["ì¡°ë¦¬ì‹¤ ì§ì›ì„ ìœ„í•œ ì¡°ì–¸"],
            "alternative_options": ["ëŒ€ì²´ ë©”ë‰´ ì œì•ˆ"]
        }}
    }}

    ì°¸ê³ ì‚¬í•­:
    - í•œêµ­ ìŒì‹ì˜ ì¼ë°˜ì ì¸ ì¬ë£Œë¥¼ ê³ ë ¤í•˜ì„¸ìš”
    - ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° ì„±ë¶„(ì†ŒìŠ¤, ì–‘ë… ë“±)ë„ ì¶”ì •í•˜ì„¸ìš”
    - ì¡°ë¦¬ ê³¼ì •ì—ì„œì˜ êµì°¨ ì˜¤ì—¼ ê°€ëŠ¥ì„±ë„ ì–¸ê¸‰í•˜ì„¸ìš”
    """
    
    for i in range(max_retries + 1):
        try:
            res = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            break
        except (RateLimitError, APIConnectionError):
            if i == max_retries:
                return {"error": "API í˜¸ì¶œ ì‹¤íŒ¨"}
            time.sleep(2 ** i)
    
    try:
        content = res.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            return {"error": "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", "raw": content}
    except json.JSONDecodeError:
        return {"error": "JSON íŒŒì‹± ì˜¤ë¥˜", "raw": content}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. AI ê¸°ë°˜ ì¢…í•© ë³´ê³ ì„œ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_ai_report(
    analysis_results: List[Dict],
    source_type: str,
    api_key: str,
    model: str = "gpt-4o-mini"
) -> str:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…í•©ì ì¸ ì•Œë ˆë¥´ê¸° ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    client = OpenAI(api_key=api_key)
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    results_summary = json.dumps(analysis_results, ensure_ascii=False, indent=2)
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•™êµ ë³´ê±´êµì‚¬ì´ì ì•Œë ˆë¥´ê¸° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™êµ ê¸‰ì‹ ì•Œë ˆë¥´ê¸° ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ë¶„ì„ ëŒ€ìƒ: {source_type}
    ë¶„ì„ ê²°ê³¼: {results_summary}

    ë³´ê³ ì„œëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        í•™êµ ê¸‰ì‹ ì•Œë ˆë¥´ê¸° ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ğŸ“… ë¶„ì„ ì •ë³´
    - ë¶„ì„ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
    - ë¶„ì„ëŒ€ìƒ: {source_type}
    
    ğŸ“Š ë¶„ì„ ìš”ì•½
    [ì „ì²´ì ì¸ ë¶„ì„ ê²°ê³¼ ìš”ì•½ - 3-4ì¤„]
    
    ğŸš¨ ì•Œë ˆë¥´ê¸° ìœ„í—˜ë„ í‰ê°€
    
    ã€ê³ ìœ„í—˜ ì•Œë ˆë¥´ê¸°ã€‘
    [ìƒëª…ì„ ìœ„í˜‘í•  ìˆ˜ ìˆëŠ” ì•Œë ˆë¥´ê¸° ìƒì„¸ ì„¤ëª…]
    
    ã€ì¤‘ë“±ë„ ìœ„í—˜ ì•Œë ˆë¥´ê¸°ã€‘
    [ì£¼ì˜ê°€ í•„ìš”í•œ ì•Œë ˆë¥´ê¸° ìƒì„¸ ì„¤ëª…]
    
    ã€ê²½ë„ ìœ„í—˜ ì•Œë ˆë¥´ê¸°ã€‘
    [ê´€ë¦¬ ê°€ëŠ¥í•œ ì•Œë ˆë¥´ê¸° ì„¤ëª…]
    
    ğŸ” ìƒì„¸ ë¶„ì„ ê²°ê³¼
    
    [ê° ë©”ë‰´ë³„ ìƒì„¸ ë¶„ì„]
    
    âš ï¸ ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° ìœ ë°œ ìš”ì†Œ
    [ëˆˆì— ë„ì§€ ì•Šì§€ë§Œ ì£¼ì˜í•´ì•¼ í•  ìš”ì†Œë“¤]
    
    ğŸ’¡ ëŒ€ì²˜ ë°©ì•ˆ
    
    ã€ì¦‰ì‹œ ì‹œí–‰ì‚¬í•­ã€‘
    1. [êµ¬ì²´ì ì¸ ì¡°ì¹˜ì‚¬í•­]
    2. [êµ¬ì²´ì ì¸ ì¡°ì¹˜ì‚¬í•­]
    
    ã€ì˜ˆë°© ì¡°ì¹˜ã€‘
    - [ì¡°ë¦¬ì‹¤ì—ì„œì˜ ì˜ˆë°© ì¡°ì¹˜]
    - [ë°°ì‹ ì‹œ ì£¼ì˜ì‚¬í•­]
    - [í•™ìƒ ì§€ë„ ì‚¬í•­]
    
    ã€ì‘ê¸‰ ëŒ€ì‘ í”„ë¡œí† ì½œã€‘
    1. ê²½ë¯¸í•œ ì¦ìƒ: [ëŒ€ì²˜ë²•]
    2. ì¤‘ë“±ë„ ì¦ìƒ: [ëŒ€ì²˜ë²•]
    3. ì‹¬ê°í•œ ì¦ìƒ: [ëŒ€ì²˜ë²•]
    
    ğŸ“‹ ëŒ€ì²´ ë©”ë‰´ ì œì•ˆ
    [ì•Œë ˆë¥´ê¸° í•™ìƒì„ ìœ„í•œ ëŒ€ì²´ ë©”ë‰´ ì œì•ˆ]
    
    ğŸ“ ë¹„ìƒ ì—°ë½ë§
    - ë³´ê±´ì‹¤: ë‚´ì„  [ë²ˆí˜¸]
    - 119 êµ¬ê¸‰ëŒ€: 119
    - í•™êµ ì¸ê·¼ ë³‘ì›: [ë³‘ì›ëª…] [ì „í™”ë²ˆí˜¸]
    - ì‘ê¸‰ì˜ë£Œì •ë³´ì„¼í„°: 1339
    
    âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸
    â–¡ ì•Œë ˆë¥´ê¸° í•™ìƒ ëª…ë‹¨ í™•ì¸
    â–¡ ëŒ€ì²´ ê¸‰ì‹ ì¤€ë¹„
    â–¡ ì¡°ë¦¬ì‹¤ ì§ì› ë¸Œë¦¬í•‘
    â–¡ ë‹´ì„êµì‚¬ í†µë³´
    â–¡ ë³´ê±´ì‹¤ ì˜ì•½í’ˆ í™•ì¸
    
    ğŸ’¬ ì¶”ê°€ ê¶Œê³ ì‚¬í•­
    [ì „ë¬¸ê°€ë¡œì„œì˜ ì¶”ê°€ ì¡°ì–¸]
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­:
    1. ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±
    2. ì‹¤ì œ í•™êµ í˜„ì¥ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ë‚´ìš©
    3. ìœ„í—˜ë„ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ëª…í™•íˆ êµ¬ë¶„
    4. í•œêµ­ í•™êµ ê¸‰ì‹ í™˜ê²½ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì–¸
    """
    
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=3000
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        return f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ì˜í•™ì  ì •ë³´ ìƒì„± í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_medical_info_for_allergen(
    allergen: str,
    api_key: str,
    model: str = "gpt-4o-mini"
) -> Dict:
    """íŠ¹ì • ì•Œë ˆë¥´ê¸°ì— ëŒ€í•œ ìƒì„¸ ì˜í•™ ì •ë³´ ìƒì„±"""
    client = OpenAI(api_key=api_key)
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì†Œì•„ ì•Œë ˆë¥´ê¸° ì „ë¬¸ì˜ì…ë‹ˆë‹¤.
    {allergen} ì•Œë ˆë¥´ê¸°ì— ëŒ€í•´ í•™êµ ê´€ê³„ìë“¤ì´ ì•Œì•„ì•¼ í•  ì˜í•™ì  ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
        "medical_name": "ì˜í•™ì  ëª…ì¹­",
        "prevalence": "í•œêµ­ í•™ìƒ ìœ ë³‘ë¥ ",
        "mechanism": "ì•Œë ˆë¥´ê¸° ë°œìƒ ê¸°ì „ (ì‰½ê²Œ ì„¤ëª…)",
        "symptoms": {{
            "immediate": ["ì¦‰ê°ì  ì¦ìƒë“¤"],
            "delayed": ["ì§€ì—°ì„± ì¦ìƒë“¤"],
            "severe": ["ì‹¬ê°í•œ ì¦ìƒë“¤"]
        }},
        "onset_time": "ì¦ìƒ ë°œí˜„ ì‹œê°„",
        "cross_reactivity": ["êµì°¨ ë°˜ì‘ ê°€ëŠ¥ ë¬¼ì§ˆë“¤"],
        "diagnosis": "ì§„ë‹¨ ë°©ë²•",
        "treatment": {{
            "emergency": "ì‘ê¸‰ ì²˜ì¹˜",
            "medication": "ì‚¬ìš© ê°€ëŠ¥ ì•½ë¬¼",
            "long_term": "ì¥ê¸° ê´€ë¦¬ ë°©ë²•"
        }},
        "school_management": {{
            "prevention": ["í•™êµì—ì„œì˜ ì˜ˆë°© ì¡°ì¹˜"],
            "monitoring": ["ê´€ì°° í¬ì¸íŠ¸"],
            "documentation": ["í•„ìš” ì„œë¥˜"]
        }},
        "prognosis": "ì˜ˆí›„ ë° ì„±ì¥ì— ë”°ë¥¸ ë³€í™”"
    }}
    """
    
    try:
        res = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1500
        )
        
        content = res.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            return {"error": "ì˜í•™ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨"}
    except Exception as e:
        return {"error": f"ì˜í•™ ì •ë³´ ìƒì„± ì‹¤íŒ¨: {str(e)}"}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_pdf_text(pdf_file) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_reader = PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸ½ï¸ AI í•™êµ ê¸‰ì‹ ì•Œë ˆë¥´ê¸° ë¶„ì„ ì‹œìŠ¤í…œ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ½ï¸ AI ê¸°ë°˜ í•™êµ ê¸‰ì‹ ì•Œë ˆë¥´ê¸° ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("ì¸ê³µì§€ëŠ¥ì´ ê¸‰ì‹ ë©”ë‰´ì˜ ì•Œë ˆë¥´ê¸° ìœ„í—˜ì„ ìƒì„¸íˆ ë¶„ì„í•˜ê³  ì¢…í•© ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

# API í‚¤ í™•ì¸
if "OPENAI_API_KEY" not in st.secrets:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secretsì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

api_key = st.secrets["OPENAI_API_KEY"]

# ì‚¬ì´ë“œë°” - ì•Œë ˆë¥´ê¸° ì •ë³´ ì„¼í„°
with st.sidebar:
    st.header("ğŸ“š ì•Œë ˆë¥´ê¸° ì •ë³´ ì„¼í„°")
    
    # ì£¼ìš” ì•Œë ˆë¥´ê¸° ì„ íƒ
    st.subheader("ğŸ” ì•Œë ˆë¥´ê¸° ìƒì„¸ ì •ë³´ ì¡°íšŒ")
    selected_allergen = st.selectbox(
        "ì•Œë ˆë¥´ê¸° ì„ íƒ",
        MAJOR_ALLERGENS,
        key="allergen_select"
    )
    
    if st.button("ğŸ“‹ ì˜í•™ ì •ë³´ ì¡°íšŒ", key="get_medical_info"):
        with st.spinner(f"{selected_allergen} ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            medical_info = get_medical_info_for_allergen(selected_allergen, api_key)
            
            if "error" not in medical_info:
                st.markdown(f"### ğŸ¥ {medical_info.get('medical_name', selected_allergen)}")
                st.info(f"**ìœ ë³‘ë¥ **: {medical_info.get('prevalence', 'ì •ë³´ ì—†ìŒ')}")
                
                with st.expander("ğŸ”¬ ë°œìƒ ê¸°ì „"):
                    st.write(medical_info.get('mechanism', ''))
                
                with st.expander("âš¡ ì¦ìƒ"):
                    if medical_info.get('symptoms'):
                        st.write("**ì¦‰ê°ì  ì¦ìƒ**")
                        for s in medical_info['symptoms'].get('immediate', []):
                            st.write(f"- {s}")
                        st.write("**ì‹¬ê°í•œ ì¦ìƒ**")
                        for s in medical_info['symptoms'].get('severe', []):
                            st.write(f"- ğŸš¨ {s}")
                
                with st.expander("ğŸ’Š ì¹˜ë£Œ ë° ê´€ë¦¬"):
                    if medical_info.get('treatment'):
                        st.error(f"**ì‘ê¸‰ì²˜ì¹˜**: {medical_info['treatment'].get('emergency', '')}")
                        st.warning(f"**ì•½ë¬¼**: {medical_info['treatment'].get('medication', '')}")
                        st.success(f"**ì¥ê¸°ê´€ë¦¬**: {medical_info['treatment'].get('long_term', '')}")
                
                with st.expander("ğŸ« í•™êµ ê´€ë¦¬ ì§€ì¹¨"):
                    if medical_info.get('school_management'):
                        st.write("**ì˜ˆë°© ì¡°ì¹˜**")
                        for p in medical_info['school_management'].get('prevention', []):
                            st.write(f"âœ“ {p}")
            else:
                st.error(medical_info['error'])
    
    st.divider()
    
    # ë¹ ë¥¸ ì°¸ì¡°
    st.subheader("âš¡ ì‘ê¸‰ ëŒ€ì‘ ê°€ì´ë“œ")
    st.error("""
    **ì•„ë‚˜í•„ë½ì‹œìŠ¤ ì¦ìƒ**
    - í˜¸í¡ê³¤ë€, ëª© ì¡°ì„
    - ì „ì‹  ë‘ë“œëŸ¬ê¸°
    - í˜ˆì•• ê¸‰ë½
    - ì˜ì‹ ì €í•˜
    
    **ì¦‰ì‹œ ì¡°ì¹˜**
    1. 119 ì‹ ê³ 
    2. ì—í”¼íœ íˆ¬ì—¬
    3. í‰í‰í•˜ê²Œ ëˆ•íˆê¸°
    4. í•˜ì§€ ê±°ìƒ
    """)

# ë©”ì¸ ì½˜í…ì¸ 
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„", "ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„", "ğŸ“Š Excel ë¶„ì„", "ğŸ“„ PDF ë¶„ì„"])

# íƒ­ 1: ì´ë¯¸ì§€ ë¶„ì„
with tab1:
    st.subheader("ê¸‰ì‹ ì‚¬ì§„ AI ë¶„ì„")
    st.info("ê¸‰ì‹ ì‚¬ì§„ì´ë‚˜ ì‹ë‹¨í‘œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ì•Œë ˆë¥´ê¸° ìœ„í—˜ì„ ìƒì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    uploaded_images = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True,
        key="images"
    )
    
    if uploaded_images:
        # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        cols = st.columns(min(len(uploaded_images), 3))
        for i, image in enumerate(uploaded_images):
            with cols[i % 3]:
                st.image(image, caption=f"ì´ë¯¸ì§€ {i+1}", use_container_width=True)
        
        if st.button("ğŸ¤– AI ë¶„ì„ ì‹œì‘", key="analyze_images", type="primary"):
            analysis_results = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, image in enumerate(uploaded_images):
                status_text.text(f"ì´ë¯¸ì§€ {i+1}/{len(uploaded_images)} ë¶„ì„ ì¤‘...")
                progress_bar.progress((i + 1) / len(uploaded_images))
                
                with st.spinner(f"AIê°€ ì´ë¯¸ì§€ {i+1}ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result = analyze_food_image_with_ai(image.read(), api_key)
                    
                    if "error" not in result:
                        analysis_results.append(result)
                        
                        # ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                        with st.expander(f"ğŸ“‹ ì´ë¯¸ì§€ {i+1} ë¶„ì„ ê²°ê³¼", expanded=True):
                            if "menu_items" in result:
                                for item in result["menu_items"]:
                                    st.markdown(f"### ğŸ½ï¸ {item['name']}")
                                    st.write(f"**ì¬ë£Œ**: {', '.join(item['ingredients'])}")
                                    
                                    if item.get('allergens'):
                                        st.warning(f"âš ï¸ ë°œê²¬ëœ ì•Œë ˆë¥´ê¸°: {len(item['allergens'])}ê°œ")
                                        for allergen in item['allergens']:
                                            risk_emoji = "ğŸ”´" if allergen['risk_level'] == "ê³ ë„" else "ğŸŸ¡" if allergen['risk_level'] == "ì¤‘ë“±ë„" else "ğŸŸ¢"
                                            st.write(f"{risk_emoji} **{allergen['allergen']}** (ì¶œì²˜: {allergen['source']})")
                            
                            if "overall_assessment" in result:
                                assessment = result["overall_assessment"]
                                if assessment.get("high_risk_items"):
                                    st.error(f"ğŸš¨ ê³ ìœ„í—˜ í•­ëª©: {', '.join(assessment['high_risk_items'])}")
                    else:
                        st.error(f"ì´ë¯¸ì§€ {i+1} ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            progress_bar.progress(1.0)
            status_text.text("ë¶„ì„ ì™„ë£Œ!")
            
            # AI ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            if analysis_results:
                st.success(f"âœ… {len(analysis_results)}ê°œ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
                
                with st.spinner("AIê°€ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_ai_report(analysis_results, "ì´ë¯¸ì§€ íŒŒì¼", api_key)
                
                st.markdown("### ğŸ“Š AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                st.text_area("", report, height=600, key="image_report")
                
                # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
                st.download_button(
                    "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=report.encode('utf-8'),
                    file_name=f"AI_ì•Œë ˆë¥´ê¸°ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    key="download_image_report"
                )

# íƒ­ 2: í…ìŠ¤íŠ¸ ë¶„ì„
with tab2:
    st.subheader("ê¸‰ì‹ ë©”ë‰´ í…ìŠ¤íŠ¸ AI ë¶„ì„")
    st.info("ê¸‰ì‹ ë©”ë‰´ë‚˜ ì‹ë‹¨ì„ ì…ë ¥í•˜ë©´ AIê°€ ì•Œë ˆë¥´ê¸° ìœ„í—˜ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    text_input = st.text_area(
        "ê¸‰ì‹ ë©”ë‰´ ì…ë ¥",
        placeholder="ì˜ˆ: ìŒ€ë°¥, ëœì¥ì°Œê°œ(ë‘ë¶€, íŒŒ, ë§ˆëŠ˜), ì œìœ¡ë³¶ìŒ(ë¼ì§€ê³ ê¸°, ê³ ì¶”ì¥), ê¹€ì¹˜, ìš°ìœ ",
        height=150,
        key="text_input"
    )
    
    if st.button("ğŸ¤– AI ë¶„ì„ ì‹œì‘", key="analyze_text", type="primary"):
        if text_input.strip():
            with st.spinner("AIê°€ ë©”ë‰´ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                result = analyze_text_with_ai(text_input, api_key)
            
            if "error" not in result:
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                if "identified_menus" in result:
                    st.markdown("### ğŸ½ï¸ ë©”ë‰´ë³„ ë¶„ì„ ê²°ê³¼")
                    
                    for menu in result["identified_menus"]:
                        with st.expander(f"ğŸ“Œ {menu['menu_name']}", expanded=True):
                            st.write(f"**ì¶”ì • ì¬ë£Œ**: {', '.join(menu['likely_ingredients'])}")
                            
                            if menu.get("allergen_analysis"):
                                for allergen in menu["allergen_analysis"]:
                                    confidence_emoji = "âœ…" if allergen['confidence'] == "í™•ì‹¤í•¨" else "âš ï¸" if allergen['confidence'] == "ê°€ëŠ¥ì„±ë†’ìŒ" else "â“"
                                    risk_color = "red" if allergen['risk_level'] == "ê³ ë„" else "orange" if allergen['risk_level'] == "ì¤‘ë“±ë„" else "green"
                                    
                                    st.markdown(f"{confidence_emoji} :{risk_color}[**{allergen['allergen']}**] - {allergen['confidence']}")
                                    st.write(f"   ì¶œì²˜: {allergen['source_ingredient']} | ìœ„í—˜ë„: {allergen['risk_level']}")
                                    if allergen.get('notes'):
                                        st.info(f"   ğŸ’¡ {allergen['notes']}")
                
                # ìš”ì•½ ì •ë³´
                if "summary" in result:
                    summary = result["summary"]
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ë°œê²¬ëœ ì•Œë ˆë¥´ê¸°", len(summary.get('total_allergens_found', [])))
                    with col2:
                        st.metric("ì•ˆì „ë„ ì ìˆ˜", f"{summary.get('menu_safety_score', 0)}/10")
                    with col3:
                        st.metric("ê³ ìœ„í—˜ ì•Œë ˆë¥´ê¸°", len(summary.get('high_confidence_allergens', [])))
                    
                    if summary.get('special_warnings'):
                        st.error("âš ï¸ **íŠ¹ë³„ ì£¼ì˜ì‚¬í•­**")
                        for warning in summary['special_warnings']:
                            st.write(f"- {warning}")
                
                # AI ì¢…í•© ë³´ê³ ì„œ ìƒì„±
                with st.spinner("AIê°€ ìƒì„¸ ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    report = generate_ai_report([result], "í…ìŠ¤íŠ¸ ì…ë ¥", api_key)
                
                st.markdown("### ğŸ“Š AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                st.text_area("", report, height=600, key="text_report_area")
                
                # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
                st.download_button(
                    "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=report.encode('utf-8'),
                    file_name=f"AI_ì•Œë ˆë¥´ê¸°ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    key="download_text_report"
                )
            else:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        else:
            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# íƒ­ 3: Excel ë¶„ì„
with tab3:
    st.subheader("Excel ì‹ë‹¨í‘œ AI ë¶„ì„")
    st.info("Excel í˜•ì‹ì˜ ê¸‰ì‹ ì‹ë‹¨í‘œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ì „ì²´ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    uploaded_excel = st.file_uploader(
        "Excel íŒŒì¼ ì—…ë¡œë“œ",
        type=["xlsx", "xls"],
        key="excel"
    )
    
    if uploaded_excel:
        try:
            df = pd.read_excel(uploaded_excel)
            st.write("ğŸ“Š Excel ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            st.dataframe(df.head(10))
            
            if st.button("ğŸ¤– AI ë¶„ì„ ì‹œì‘", key="analyze_excel", type="primary"):
                # ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
                all_text = ""
                for col in df.columns:
                    if df[col].dtype == 'object':
                        all_text += f"\n[{col}]\n"
                        all_text += "\n".join(df[col].dropna().astype(str).values) + "\n"
                
                with st.spinner("AIê°€ Excel ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result = analyze_text_with_ai(all_text, api_key)
                
                if "error" not in result:
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                    
                    # ì£¼ìš” ë¶„ì„ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ í‘œì‹œ
                    if "identified_menus" in result:
                        allergen_data = []
                        for menu in result["identified_menus"]:
                            for allergen in menu.get("allergen_analysis", []):
                                allergen_data.append({
                                    "ë©”ë‰´": menu["menu_name"],
                                    "ì•Œë ˆë¥´ê¸°": allergen["allergen"],
                                    "í™•ì‹¤ë„": allergen["confidence"],
                                    "ìœ„í—˜ë„": allergen["risk_level"],
                                    "ì¶œì²˜": allergen["source_ingredient"],
                                    "ë¹„ê³ ": allergen.get("notes", "")
                                })
                        
                        if allergen_data:
                            allergen_df = pd.DataFrame(allergen_data)
                            st.markdown("### ğŸ” ì•Œë ˆë¥´ê¸° ë¶„ì„ ê²°ê³¼")
                            st.dataframe(
                                allergen_df.style.applymap(
                                    lambda x: 'background-color: #ffcccc' if x == "ê³ ë„" else 
                                             'background-color: #fff3cd' if x == "ì¤‘ë“±ë„" else 
                                             'background-color: #d4edda' if x == "ê²½ë„" else '',
                                    subset=['ìœ„í—˜ë„']
                                ),
                                use_container_width=True
                            )
                    
                    # AI ì¢…í•© ë³´ê³ ì„œ ìƒì„±
                    with st.spinner("AIê°€ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        report = generate_ai_report([result], "Excel íŒŒì¼", api_key)
                    
                    st.markdown("### ğŸ“Š AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                    st.text_area("", report, height=600, key="excel_report_area")
                    
                    # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
                    st.download_button(
                        "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=report.encode('utf-8'),
                        file_name=f"AI_ì•Œë ˆë¥´ê¸°ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        key="download_excel_report"
                    )
                else:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
        except Exception as e:
            st.error(f"Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")

# íƒ­ 4: PDF ë¶„ì„
with tab4:
    st.subheader("PDF ì‹ë‹¨í‘œ AI ë¶„ì„")
    st.info("PDF í˜•ì‹ì˜ ê¸‰ì‹ ì‹ë‹¨í‘œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    uploaded_pdf = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=["pdf"],
        key="pdf"
    )
    
    if uploaded_pdf:
        if st.button("ğŸ¤– AI ë¶„ì„ ì‹œì‘", key="analyze_pdf", type="primary"):
            with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                pdf_text = extract_pdf_text(uploaded_pdf)
            
            if "ì˜¤ë¥˜" not in pdf_text:
                st.write("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
                st.text_area("", pdf_text[:1000] + "...", height=150, key="pdf_preview")
                
                with st.spinner("AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result = analyze_text_with_ai(pdf_text, api_key)
                
                if "error" not in result:
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                    
                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    if "summary" in result:
                        summary = result["summary"]
                        if summary.get('total_allergens_found'):
                            st.warning(f"âš ï¸ ë°œê²¬ëœ ì•Œë ˆë¥´ê¸°: {', '.join(summary['total_allergens_found'])}")
                        
                        if summary.get('special_warnings'):
                            for warning in summary['special_warnings']:
                                st.error(f"ğŸš¨ {warning}")
                    
                    # AI ì¢…í•© ë³´ê³ ì„œ ìƒì„±
                    with st.spinner("AIê°€ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        report = generate_ai_report([result], "PDF íŒŒì¼", api_key)
                    
                    st.markdown("### ğŸ“Š AI ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                    st.text_area("", report, height=600, key="pdf_report_area")
                    
                    # ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
                    st.download_button(
                        "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=report.encode('utf-8'),
                        file_name=f"AI_ì•Œë ˆë¥´ê¸°ë¶„ì„ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain",
                        key="download_pdf_report"
                    )
                else:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            else:
                st.error(pdf_text)

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
with st.expander("ğŸ“‹ ì‹œìŠ¤í…œ ì‚¬ìš© ì•ˆë‚´"):
    st.markdown("""
    ### ğŸ¤– AI ë¶„ì„ ì‹œìŠ¤í…œ íŠ¹ì§•
    - **ê³ ê¸‰ ì´ë¯¸ì§€ ì¸ì‹**: ìŒì‹ ì‚¬ì§„ì—ì„œ ì¬ë£Œì™€ ì¡°ë¦¬ë²•ì„ ì¶”ì •
    - **ì»¨í…ìŠ¤íŠ¸ ì´í•´**: í•œêµ­ ê¸‰ì‹ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë¶„ì„
    - **ìˆ¨ê²¨ì§„ ì•Œë ˆë¥´ê¸° íƒì§€**: ì†ŒìŠ¤, ì–‘ë… ë“±ì— ìˆ¨ì–´ìˆëŠ” ì•Œë ˆë¥´ê¸° ì„±ë¶„ ë°œê²¬
    - **ì¢…í•© ë³´ê³ ì„œ**: ì‹¤ë¬´ì— ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ ìƒì„¸ ë³´ê³ ì„œ ìë™ ìƒì„±
    
    ### ğŸ¯ ì‚¬ìš© ë°©ë²•
    1. ë¶„ì„í•˜ê³ ì í•˜ëŠ” ìë£Œ í˜•íƒœì— ë§ëŠ” íƒ­ ì„ íƒ
    2. íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥
    3. AI ë¶„ì„ ì‹œì‘ ë²„íŠ¼ í´ë¦­
    4. ìƒì„±ëœ ë³´ê³ ì„œ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    
    ### âš ï¸ ì¤‘ìš” ì•ˆì „ ìˆ˜ì¹™
    - AI ë¶„ì„ ê²°ê³¼ëŠ” **ì°¸ê³ ìš©**ì…ë‹ˆë‹¤
    - ì‹¬ê°í•œ ì•Œë ˆë¥´ê¸°ê°€ ìˆëŠ” í•™ìƒì€ **ì „ë¬¸ì˜ ìƒë‹´** í•„ìˆ˜
    - ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê²½ìš° **ì„­ì·¨ ê¸ˆì§€** ì›ì¹™
    - ì •ê¸°ì ì¸ **ì•Œë ˆë¥´ê¸° ê²€ì‚¬** ê¶Œì¥
    
    ### ğŸ“ ë¹„ìƒ ì—°ë½ì²˜
    - **119**: ì‘ê¸‰ìƒí™© (ì•„ë‚˜í•„ë½ì‹œìŠ¤, í˜¸í¡ê³¤ë€)
    - **1339**: ì‘ê¸‰ì˜ë£Œì •ë³´ì„¼í„°
    - **í•™êµ ë³´ê±´ì‹¤**: ì¦‰ê°ì ì¸ 1ì°¨ ëŒ€ì‘
    """)

# ì¶”ê°€ ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .stButton > button[kind="primary"] {
        background-color: #ff4b4b;
        color: white;
        font-weight: bold;
    }
    .stExpander {
        border: 1px solid #ddd;
        border-radius: 10px;
        margin-bottom: 10px;
    }
    div[data-testid="metric-container"] {
        border: 1px solid #ddd;
        padding: 10px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)
